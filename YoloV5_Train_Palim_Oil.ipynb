{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aIykUb183gz",
        "outputId": "37f2c593-01fa-4763-94d0-19e8fae46644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acoTIZkpG3_p",
        "outputId": "eb418328-acbe-4707-b185-e2423c285fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'palm-oil-dataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gerarldoindra/palm-oil-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vebtlA-N9CCf",
        "outputId": "f7537d84-7ff6-4f16-af6f-f024b314cdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 5)) (3.1.40)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 13)) (1.11.3)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 15)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 16)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 17)) (4.66.1)\n",
            "Requirement already satisfied: ultralytics>=8.0.147 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 18)) (8.0.200)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/palm-oil-dataset/req/requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r /content/palm-oil-dataset/req/requirements.txt (line 5)) (4.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/palm-oil-dataset/req/requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/palm-oil-dataset/req/requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/palm-oil-dataset/req/requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/palm-oil-dataset/req/requirements.txt (line 12)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r /content/palm-oil-dataset/req/requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /content/palm-oil-dataset/req/requirements.txt (line 27)) (2023.3.post1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r /content/palm-oil-dataset/req/requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r /content/palm-oil-dataset/req/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r /content/palm-oil-dataset/req/requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install -r /content/palm-oil-dataset/req/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6QpUTxe89PFN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from yolov5 import utils\n",
        "import torch\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WDW8KcFmAbfy"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = \"yolov5_train\"\n",
        "BASE_MODEL = \"yolov5m6.pt\"\n",
        "TRAIN_BATCH = 32\n",
        "TRAIN_EPOCHS = 200\n",
        "VAL_BATCH = 64\n",
        "NOTES_PATH = \"/content/palm-oil-dataset/notes.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqwYQWpRAq4S",
        "outputId": "4cc40d4e-996c-4162-e0c4-12cb03c35739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: /content/palm-oil-dataset/train/images\n",
            "test: /content/palm-oil-dataset/test/images\n",
            "val: /content/palm-oil-dataset/valid/images\n",
            "\n",
            "nc: 7\n",
            "names: ['Ripe', 'Unripe', 'overripe', 'ripe', 'ripe', 'underripe', 'unripe']\n"
          ]
        }
      ],
      "source": [
        "descr_darknet = json.load(open(NOTES_PATH))\n",
        "\n",
        "train_path = \"/content/palm-oil-dataset/train/images\"\n",
        "test_path = \"/content/palm-oil-dataset/test/images\"\n",
        "valid_path = \"/content/palm-oil-dataset/valid/images\"\n",
        "\n",
        "nc = len(descr_darknet[\"categories\"])\n",
        "names = [category[\"name\"] for category in descr_darknet[\"categories\"]]\n",
        "\n",
        "print(\n",
        "    f\"train: {train_path}\\n\"\n",
        "    f\"test: {test_path}\\n\"\n",
        "    f\"val: {valid_path}\\n\\n\"\n",
        "    f\"nc: {nc}\\n\"\n",
        "    f\"names: {names}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tRSAVXgOLkSy"
      },
      "outputs": [],
      "source": [
        "with open(\"data.yaml\", \"w\") as file:\n",
        "    yaml.dump({\n",
        "        \"train\": train_path,\n",
        "        \"test\": test_path,\n",
        "        \"val\": valid_path,\n",
        "        \"nc\": nc,\n",
        "        \"names\": [f'{name}' for name in names]\n",
        "    }, stream=file, default_flow_style=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MBEiBzLJMHG2"
      },
      "outputs": [],
      "source": [
        "wildcard = f\"{PROJECT_NAME}/feature_extraction*\"\n",
        "! rm -r $wildcard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M-W05uQMJM4",
        "outputId": "6f30c9f8-6e2d-47d6-d8f9-2969c9decb8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m6.pt, cfg=, data=data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=200, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5_train, name=feature_extraction, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[12], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-227-ge4df1ec Python-3.10.12 torch-2.1.0+cu118 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5_train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n",
            "  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n",
            "  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n",
            " 10                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            " 11                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n",
            " 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n",
            " 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n",
            " 33  [23, 26, 29, 32]  1     69264  models.yolo.Detect                      [7, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\n",
            "Model summary: 379 layers, 35310576 parameters, 35310576 gradients, 49.3 GFLOPs\n",
            "\n",
            "Transferred 619/627 items from yolov5m6.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.cv1.conv.weight\n",
            "freezing model.2.cv1.bn.weight\n",
            "freezing model.2.cv1.bn.bias\n",
            "freezing model.2.cv2.conv.weight\n",
            "freezing model.2.cv2.bn.weight\n",
            "freezing model.2.cv2.bn.bias\n",
            "freezing model.2.cv3.conv.weight\n",
            "freezing model.2.cv3.bn.weight\n",
            "freezing model.2.cv3.bn.bias\n",
            "freezing model.2.m.0.cv1.conv.weight\n",
            "freezing model.2.m.0.cv1.bn.weight\n",
            "freezing model.2.m.0.cv1.bn.bias\n",
            "freezing model.2.m.0.cv2.conv.weight\n",
            "freezing model.2.m.0.cv2.bn.weight\n",
            "freezing model.2.m.0.cv2.bn.bias\n",
            "freezing model.2.m.1.cv1.conv.weight\n",
            "freezing model.2.m.1.cv1.bn.weight\n",
            "freezing model.2.m.1.cv1.bn.bias\n",
            "freezing model.2.m.1.cv2.conv.weight\n",
            "freezing model.2.m.1.cv2.bn.weight\n",
            "freezing model.2.m.1.cv2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.cv1.conv.weight\n",
            "freezing model.4.cv1.bn.weight\n",
            "freezing model.4.cv1.bn.bias\n",
            "freezing model.4.cv2.conv.weight\n",
            "freezing model.4.cv2.bn.weight\n",
            "freezing model.4.cv2.bn.bias\n",
            "freezing model.4.cv3.conv.weight\n",
            "freezing model.4.cv3.bn.weight\n",
            "freezing model.4.cv3.bn.bias\n",
            "freezing model.4.m.0.cv1.conv.weight\n",
            "freezing model.4.m.0.cv1.bn.weight\n",
            "freezing model.4.m.0.cv1.bn.bias\n",
            "freezing model.4.m.0.cv2.conv.weight\n",
            "freezing model.4.m.0.cv2.bn.weight\n",
            "freezing model.4.m.0.cv2.bn.bias\n",
            "freezing model.4.m.1.cv1.conv.weight\n",
            "freezing model.4.m.1.cv1.bn.weight\n",
            "freezing model.4.m.1.cv1.bn.bias\n",
            "freezing model.4.m.1.cv2.conv.weight\n",
            "freezing model.4.m.1.cv2.bn.weight\n",
            "freezing model.4.m.1.cv2.bn.bias\n",
            "freezing model.4.m.2.cv1.conv.weight\n",
            "freezing model.4.m.2.cv1.bn.weight\n",
            "freezing model.4.m.2.cv1.bn.bias\n",
            "freezing model.4.m.2.cv2.conv.weight\n",
            "freezing model.4.m.2.cv2.bn.weight\n",
            "freezing model.4.m.2.cv2.bn.bias\n",
            "freezing model.4.m.3.cv1.conv.weight\n",
            "freezing model.4.m.3.cv1.bn.weight\n",
            "freezing model.4.m.3.cv1.bn.bias\n",
            "freezing model.4.m.3.cv2.conv.weight\n",
            "freezing model.4.m.3.cv2.bn.weight\n",
            "freezing model.4.m.3.cv2.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.cv1.conv.weight\n",
            "freezing model.6.cv1.bn.weight\n",
            "freezing model.6.cv1.bn.bias\n",
            "freezing model.6.cv2.conv.weight\n",
            "freezing model.6.cv2.bn.weight\n",
            "freezing model.6.cv2.bn.bias\n",
            "freezing model.6.cv3.conv.weight\n",
            "freezing model.6.cv3.bn.weight\n",
            "freezing model.6.cv3.bn.bias\n",
            "freezing model.6.m.0.cv1.conv.weight\n",
            "freezing model.6.m.0.cv1.bn.weight\n",
            "freezing model.6.m.0.cv1.bn.bias\n",
            "freezing model.6.m.0.cv2.conv.weight\n",
            "freezing model.6.m.0.cv2.bn.weight\n",
            "freezing model.6.m.0.cv2.bn.bias\n",
            "freezing model.6.m.1.cv1.conv.weight\n",
            "freezing model.6.m.1.cv1.bn.weight\n",
            "freezing model.6.m.1.cv1.bn.bias\n",
            "freezing model.6.m.1.cv2.conv.weight\n",
            "freezing model.6.m.1.cv2.bn.weight\n",
            "freezing model.6.m.1.cv2.bn.bias\n",
            "freezing model.6.m.2.cv1.conv.weight\n",
            "freezing model.6.m.2.cv1.bn.weight\n",
            "freezing model.6.m.2.cv1.bn.bias\n",
            "freezing model.6.m.2.cv2.conv.weight\n",
            "freezing model.6.m.2.cv2.bn.weight\n",
            "freezing model.6.m.2.cv2.bn.bias\n",
            "freezing model.6.m.3.cv1.conv.weight\n",
            "freezing model.6.m.3.cv1.bn.weight\n",
            "freezing model.6.m.3.cv1.bn.bias\n",
            "freezing model.6.m.3.cv2.conv.weight\n",
            "freezing model.6.m.3.cv2.bn.weight\n",
            "freezing model.6.m.3.cv2.bn.bias\n",
            "freezing model.6.m.4.cv1.conv.weight\n",
            "freezing model.6.m.4.cv1.bn.weight\n",
            "freezing model.6.m.4.cv1.bn.bias\n",
            "freezing model.6.m.4.cv2.conv.weight\n",
            "freezing model.6.m.4.cv2.bn.weight\n",
            "freezing model.6.m.4.cv2.bn.bias\n",
            "freezing model.6.m.5.cv1.conv.weight\n",
            "freezing model.6.m.5.cv1.bn.weight\n",
            "freezing model.6.m.5.cv1.bn.bias\n",
            "freezing model.6.m.5.cv2.conv.weight\n",
            "freezing model.6.m.5.cv2.bn.weight\n",
            "freezing model.6.m.5.cv2.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.cv1.conv.weight\n",
            "freezing model.8.cv1.bn.weight\n",
            "freezing model.8.cv1.bn.bias\n",
            "freezing model.8.cv2.conv.weight\n",
            "freezing model.8.cv2.bn.weight\n",
            "freezing model.8.cv2.bn.bias\n",
            "freezing model.8.cv3.conv.weight\n",
            "freezing model.8.cv3.bn.weight\n",
            "freezing model.8.cv3.bn.bias\n",
            "freezing model.8.m.0.cv1.conv.weight\n",
            "freezing model.8.m.0.cv1.bn.weight\n",
            "freezing model.8.m.0.cv1.bn.bias\n",
            "freezing model.8.m.0.cv2.conv.weight\n",
            "freezing model.8.m.0.cv2.bn.weight\n",
            "freezing model.8.m.0.cv2.bn.bias\n",
            "freezing model.8.m.1.cv1.conv.weight\n",
            "freezing model.8.m.1.cv1.bn.weight\n",
            "freezing model.8.m.1.cv1.bn.bias\n",
            "freezing model.8.m.1.cv2.conv.weight\n",
            "freezing model.8.m.1.cv2.bn.weight\n",
            "freezing model.8.m.1.cv2.bn.bias\n",
            "freezing model.9.conv.weight\n",
            "freezing model.9.bn.weight\n",
            "freezing model.9.bn.bias\n",
            "freezing model.10.cv1.conv.weight\n",
            "freezing model.10.cv1.bn.weight\n",
            "freezing model.10.cv1.bn.bias\n",
            "freezing model.10.cv2.conv.weight\n",
            "freezing model.10.cv2.bn.weight\n",
            "freezing model.10.cv2.bn.bias\n",
            "freezing model.10.cv3.conv.weight\n",
            "freezing model.10.cv3.bn.weight\n",
            "freezing model.10.cv3.bn.bias\n",
            "freezing model.10.m.0.cv1.conv.weight\n",
            "freezing model.10.m.0.cv1.bn.weight\n",
            "freezing model.10.m.0.cv1.bn.bias\n",
            "freezing model.10.m.0.cv2.conv.weight\n",
            "freezing model.10.m.0.cv2.bn.weight\n",
            "freezing model.10.m.0.cv2.bn.bias\n",
            "freezing model.10.m.1.cv1.conv.weight\n",
            "freezing model.10.m.1.cv1.bn.weight\n",
            "freezing model.10.m.1.cv1.bn.bias\n",
            "freezing model.10.m.1.cv2.conv.weight\n",
            "freezing model.10.m.1.cv2.bn.weight\n",
            "freezing model.10.m.1.cv2.bn.bias\n",
            "freezing model.11.cv1.conv.weight\n",
            "freezing model.11.cv1.bn.weight\n",
            "freezing model.11.cv1.bn.bias\n",
            "freezing model.11.cv2.conv.weight\n",
            "freezing model.11.cv2.bn.weight\n",
            "freezing model.11.cv2.bn.bias\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 103 weight(decay=0.0), 107 weight(decay=0.0005), 107 bias\n"
          ]
        }
      ],
      "source": [
        "! python yolov5/train.py --batch $TRAIN_BATCH --epochs $TRAIN_EPOCHS --data \"data.yaml\" --weights $BASE_MODEL --project $PROJECT_NAME --name 'feature_extraction' --cache --freeze 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBndI4TnMMEa"
      },
      "outputs": [],
      "source": [
        "# Delete old results\n",
        "wildcard = f\"{PROJECT_NAME}/validation_on_test_data*\"\n",
        "! rm -r $wildcard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-u6xM2eMQQ6"
      },
      "outputs": [],
      "source": [
        "WEIGHTS_BEST = f\"{PROJECT_NAME}/feature_extraction/weights/best.pt\"\n",
        "! python yolov5/val.py --weights $WEIGHTS_BEST --batch $VAL_BATCH --data 'data.yaml' --task test --project $PROJECT_NAME --name 'validation_on_test_data' --augment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQwQ9EyOMSCp"
      },
      "outputs": [],
      "source": [
        "# Delete old results\n",
        "wildcard = f\"{PROJECT_NAME}/detect_test*\"\n",
        "! rm -r $wildcard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U1O53cQMUdZ"
      },
      "outputs": [],
      "source": [
        "! python yolov5/detect.py --weights $WEIGHTS_BEST --conf 0.6 --source 'test/images' --project $PROJECT_NAME --name 'detect_test' --augment --line=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk5GnKg6MWYp"
      },
      "outputs": [],
      "source": [
        "def read_images(dirpath):\n",
        "  images = []\n",
        "  for img_filename in os.listdir(dirpath):\n",
        "    images.append(mpimg.imread(f\"{dirpath}/{img_filename}\"))\n",
        "  return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQI2RaeHMZCh"
      },
      "outputs": [],
      "source": [
        "def label_test_images(test_images_path, test_labels_path, classes):\n",
        "  test_images = os.listdir(test_images_path)\n",
        "  labeled_images = []\n",
        "\n",
        "  for idx, test_image_filename in enumerate(test_images):\n",
        "    image = mpimg.imread(f\"{test_images_path}/{test_image_filename}\")\n",
        "\n",
        "    x_shape, y_shape = image.shape[1], image.shape[0]\n",
        "\n",
        "    test_label_filename = f\"{test_image_filename[:-4]}.txt\"\n",
        "\n",
        "    with open(f\"{test_labels_path}/{test_label_filename}\", \"r\") as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "      for line in lines:\n",
        "        # Parse line\n",
        "        box = line.split()\n",
        "        class_idx = box[0]\n",
        "\n",
        "        class_name = names[int(class_idx)]\n",
        "        x_center, y_center, box_w, box_h = int(float(box[1])*x_shape), int(float(box[2])*y_shape), int(float(box[3])*x_shape), int(float(box[3])*y_shape)\n",
        "        x1, y1, x2, y2 = x_center-int(box_w/2), y_center-int(box_h/2), x_center+int(box_w/2), y_center+int(box_h/2)\n",
        "\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
        "        cv2.putText(image, class_name, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 3)\n",
        "\n",
        "    labeled_images.append(image)\n",
        "\n",
        "  return labeled_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwHNLSYaMaoD"
      },
      "outputs": [],
      "source": [
        "detect_path = f\"{PROJECT_NAME}/detect_test\"\n",
        "test_images_path = f\"/content/palm-oil-dataset/test/images\"\n",
        "test_labels_path = f\"/content/palm-oil-dataset/test/labels\"\n",
        "\n",
        "detected_images = read_images(detect_path)\n",
        "test_labeled_images = label_test_images(test_images_path, test_labels_path, classes=names)\n",
        "\n",
        "stacked_images = [np.hstack([detected_images[idx], test_labeled_images[idx]]) for idx in range(len(detected_images))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVvMRt1qMdID"
      },
      "outputs": [],
      "source": [
        "for image in stacked_images:\n",
        "  fig = plt.figure(figsize=(40, 15))\n",
        "  ax1 = fig.add_subplot(2,2,1)\n",
        "  ax1.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4Ixdl1YMffS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}